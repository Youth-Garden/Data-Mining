import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans, DBSCAN

# Local modules
from features.data import load_data, scale_continuous
from features.viz import run_pca, run_tsne
from features.clustering import evaluate_clustering
from features.modeling import run_classification
from features.utils import auto_table_height
from features.notebook_runner import run_notebook, notebook_to_html

st.set_page_config(page_title="Glass Data Mining Demo", layout="wide")
sns.set_style("whitegrid")
# Smooth scrolling for in-page anchor links
st.markdown(
    """
    <style>
    html { scroll-behavior: smooth; }
    .anchor { scroll-margin-top: 80px; }
    </style>
    """,
    unsafe_allow_html=True,
)

# === Sidebar ===
st.sidebar.title("Glass Data Mining Demo")
st.sidebar.markdown("### ƒêi·ªÅu h∆∞·ªõng")
st.sidebar.markdown(
    """
    - [Gi·ªõi thi·ªáu](#gioi-thieu)
    - [1) Kh·∫£o s√°t d·ªØ li·ªáu](#khao-sat-du-lieu)
    - [2) Tr·ª±c quan h√≥a](#truc-quan-hoa)
    - [3) Ph√¢n lo·∫°i](#phan-loai)
    - [4) Gom c·ª•m](#gom-cum)
    """
)
st.sidebar.markdown("---")
st.sidebar.caption("Source: glass-data.csv")

# Load data
try:
    df = load_data()
except Exception as e:
    st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu: {e}")
    st.stop()

# Common derived data
X_cont, X_scaled = scale_continuous(df)
y = df["Type"].values

st.markdown('<div id="gioi-thieu" class="anchor"></div>', unsafe_allow_html=True)
st.title("Glass Data Mining Demo")
st.markdown(
    """
    ·ª®ng d·ª•ng web tr√¨nh di·ªÖn c√°c b∆∞·ªõc khai ph√° d·ªØ li·ªáu tr√™n b·ªô d·ªØ li·ªáu k√≠nh:
    - Kh·∫£o s√°t d·ªØ li·ªáu c∆° b·∫£n (shape, dtype, th·ªëng k√™, ph√¢n b·ªë nh√£n)
    - Tr·ª±c quan h√≥a v·ªõi PCA v√† t-SNE
    - Hu·∫•n luy·ªán v√† so s√°nh c√°c m√¥ h√¨nh ph√¢n lo·∫°i (KNN, Random Forest, SVM)
    - Gom c·ª•m v·ªõi K-Means v√† DBSCAN, k√®m c√°c ƒë·ªô ƒëo F1, ARI, NMI
    """
)

c1, c2, c3 = st.columns(3)
with c1:
    st.metric("S·ªë m·∫´u", df.shape[0])
with c2:
    st.metric("S·ªë thu·ªôc t√≠nh", df.shape[1])
with c3:
    st.metric("S·ªë l·ªõp (Type)", int(df["Type"].nunique()))

st.subheader("ƒê·ªÅ b√†i")
st.markdown(
    """
    1) Kh·∫£o s√°t v√† x·ª≠ l√Ω d·ªØ li·ªáu: k√≠ch th∆∞·ªõc, ki·ªÉu d·ªØ li·ªáu, ph√¢n b·ªë nh√£n, th·ªëng k√™.
    2) Tr·ª±c quan h√≥a: gi·∫£m chi·ªÅu (PCA, t-SNE) v√† bi·ªÉu di·ªÖn ph√¢n b·ªë.
    3) Ph√¢n lo·∫°i: so s√°nh KNN, Random Forest, SVM b·∫±ng 10-fold CV (F1 Macro).
    4) Gom c·ª•m: K-Means v√† DBSCAN, ƒë√°nh gi√° b·∫±ng F1 Macro, ARI, NMI.
    """
)

st.subheader("Xu·∫•t/ t·∫£i d·ªØ li·ªáu")
col_a, col_b = st.columns(2)
with col_a:
    st.write("T·∫£i b·∫£n CSV g·ªëc (tab-separated)")
    try:
        with open("glass-data.csv", "rb") as f:
            st.download_button("T·∫£i glass-data.csv", f, file_name="glass-data.csv", mime="text/tab-separated-values")
    except Exception:
        st.caption("Kh√¥ng t√¨m th·∫•y glass-data.csv trong th∆∞ m·ª•c hi·ªán t·∫°i.")
with col_b:
    st.write("T·∫£i b·∫£n CSV ƒë√£ chu·∫©n h√≥a t√™n c·ªôt")
    cleaned_csv = df.to_csv(index=False)
    st.download_button("T·∫£i cleaned_glass.csv", cleaned_csv, file_name="cleaned_glass.csv", mime="text/csv")

st.markdown("---")

with st.expander("**K·∫øt qu·∫£ t·ª´ Notebook**", expanded=True):
    try:
        with st.spinner("Ch·∫°y notebook..."):
            # kernel_name=None will auto-detect from notebook metadata or use system default
            out_nb = run_notebook("main.ipynb", "outputs/main_executed.ipynb", kernel_name=None)
            try:
                html_preview = notebook_to_html(out_nb)
            except Exception:
                html_preview = None
        st.success("Notebook ƒë√£ ch·∫°y xong.")
        # N√∫t t·∫£i notebook ƒë√£ ch·∫°y
    
        # Xem tr∆∞·ªõc HTML trong expander (n·∫øu convert th√†nh c√¥ng)
        if html_preview:
            with st.expander("üëÄ Xem tr∆∞·ªõc chi ti·∫øt notebook (HTML)", expanded=False):
                st.components.v1.html(html_preview, height=700, scrolling=True)
    except Exception as e:
        st.error(f"L·ªói khi ch·∫°y notebook: {e}\nVui l√≤ng c√†i ƒë·∫∑t: pip install nbformat nbclient nbconvert")

# Manual re-run button
if st.button("‚ñ∂ Ch·∫°y main.ipynb l·∫°i (th·ªß c√¥ng)", key="manual_nb_run"):
    try:
        with st.spinner("ƒêang ch·∫°y notebook... (l·∫ßn ƒë·∫ßu c√≥ th·ªÉ h∆°i l√¢u)"):
            out_nb = run_notebook("main.ipynb", "outputs/main_executed.ipynb", kernel_name=None)
            try:
                html_preview = notebook_to_html(out_nb)
            except Exception:
                html_preview = None
        st.success("Notebook ƒë√£ ch·∫°y xong.")
    
        # Xem tr∆∞·ªõc HTML trong expander (n·∫øu convert th√†nh c√¥ng)
        if html_preview:
            with st.expander("üëÄ Xem tr∆∞·ªõc chi ti·∫øt notebook (HTML)", expanded=False):
                st.components.v1.html(html_preview, height=700, scrolling=True)
    except Exception as e:
        st.error(f"L·ªói khi ch·∫°y notebook: {e}\nVui l√≤ng c√†i ƒë·∫∑t: pip install nbformat nbclient nbconvert")

st.markdown('<div id="khao-sat-du-lieu" class="anchor"></div>', unsafe_allow_html=True)
st.header("1) Kh·∫£o s√°t d·ªØ li·ªáu")

st.subheader("B·∫£ng d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß")
st.dataframe(df, width="stretch", height=auto_table_height(len(df)))
st.caption(f"Hi·ªÉn th·ªã to√†n b·ªô {len(df)} d√≤ng.")

c1, c2 = st.columns(2)
with c1:
    st.subheader("Th√¥ng tin chung")
    st.write("Shape:", df.shape)
    st.write("Ki·ªÉu d·ªØ li·ªáu:")
    st.write(df.dtypes)
st.write("Ph√¢n b·ªë nh√£n (Type):")
type_counts = df["Type"].value_counts().sort_index()
st.bar_chart(type_counts)
with c2:
    st.subheader("Th·ªëng k√™ m√¥ t·∫£ (c√°c c·ªôt s·ªë)")
    st.dataframe(df.describe().T, width="stretch")

st.markdown('<div id="truc-quan-hoa" class="anchor"></div>', unsafe_allow_html=True)
st.header("2) Tr·ª±c quan h√≥a")

show_pca = st.checkbox("Hi·ªÉn th·ªã PCA 2D", value=True)
show_tsne = st.checkbox("Hi·ªÉn th·ªã t-SNE 2D (ch·∫≠m h∆°n)", value=False)
label_palette = sns.color_palette("tab10", n_colors=int(df["Type"].nunique()))

if show_pca:
    X_pca, pca = run_pca(X_scaled)
    fig, ax = plt.subplots(figsize=(7, 5))
    for idx, t in enumerate(sorted(df["Type"].unique())):
        mask = df["Type"] == t
        ax.scatter(
            X_pca[mask, 0],
            X_pca[mask, 1],
            s=60,
            label=f"Type {t}",
            c=[label_palette[idx]],
            edgecolors="black",
            linewidths=0.3,
            alpha=0.8,
        )
    ax.set_xlabel(f"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)")
    ax.set_ylabel(f"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)")
    ax.set_title("PCA Visualization")
    ax.legend()
    ax.grid(True, alpha=0.3)
    st.pyplot(fig)

if show_tsne:
    with st.spinner("ƒêang ch·∫°y t-SNE, vui l√≤ng ƒë·ª£i..."):
        X_tsne = run_tsne(X_scaled)
    fig, ax = plt.subplots(figsize=(7, 5))
    for idx, t in enumerate(sorted(df["Type"].unique())):
        mask = df["Type"] == t
        ax.scatter(
            X_tsne[mask, 0],
            X_tsne[mask, 1],
            s=60,
            label=f"Type {t}",
            c=[label_palette[idx]],
            edgecolors="black",
            linewidths=0.3,
            alpha=0.8,
        )
    ax.set_xlabel("t-SNE 1")
    ax.set_ylabel("t-SNE 2")
    ax.set_title("t-SNE Visualization")
    ax.legend()
    ax.grid(True, alpha=0.3)
    st.pyplot(fig)

st.markdown('<div id="phan-loai" class="anchor"></div>', unsafe_allow_html=True)
st.header("3) Ph√¢n lo·∫°i (Classification)")

st.info("Theo ƒë·ªÅ b√†i: d√πng 10-fold Cross Validation (c√≥ th·ªÉ gi·∫£m ƒë·ªÉ ch·∫°y nhanh h∆°n).")
cv_k = st.slider("S·ªë folds (KFold)", min_value=3, max_value=10, value=10, step=1)

if st.button("Ch·∫°y hu·∫•n luy·ªán & so s√°nh m√¥ h√¨nh"):
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
        progress = st.progress(0)
        def _cb(i, total):
            progress.progress(int(i / total * 100))
        results = run_classification(df, cv_k=cv_k, progress_callback=_cb)
    st.subheader("K·∫øt qu·∫£")
    st.dataframe(results, width="stretch")
    st.download_button("T·∫£i k·∫øt qu·∫£ (CSV)", results.to_csv(index=False), file_name="classification_results.csv", mime="text/csv")

st.markdown('<div id="gom-cum" class="anchor"></div>', unsafe_allow_html=True)
st.header("4) Gom c·ª•m (Clustering)")

tab1, tab2 = st.tabs(["K-Means", "DBSCAN"])

with tab1:
    k_default = int(df["Type"].nunique())
    n_clusters = st.number_input("S·ªë c·ª•m (k)", min_value=2, max_value=10, value=k_default, step=1)
    if st.button("Ch·∫°y K-Means"):
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=20)
        km_labels = kmeans.fit_predict(X_scaled)
        km_eval = evaluate_clustering(y, km_labels)
        st.write("ƒê√°nh gi√°:")
        st.json(km_eval)

        X_pca, _ = run_pca(X_scaled)
        fig, ax = plt.subplots(figsize=(6, 5))
        sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=km_labels, cmap="viridis", s=60)
        ax.set_title("KMeans Clusters (PCA 2D)")
        ax.set_xlabel("PC1"); ax.set_ylabel("PC2")
        plt.colorbar(sc, label="Cluster")
        st.pyplot(fig)

with tab2:
    eps = st.slider("eps", min_value=0.3, max_value=2.0, value=1.0, step=0.1)
    min_samples = st.slider("min_samples", min_value=3, max_value=20, value=5, step=1)
    if st.button("Ch·∫°y DBSCAN"):
        db = DBSCAN(eps=eps, min_samples=min_samples)
        db_labels = db.fit_predict(X_scaled)
        db_eval = evaluate_clustering(y, db_labels)
        st.write("ƒê√°nh gi√°:")
        st.json(db_eval)

        X_pca, _ = run_pca(X_scaled)
        fig, ax = plt.subplots(figsize=(6, 5))
        sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=db_labels, cmap="viridis", s=60)
        ax.set_title("DBSCAN Clusters (PCA 2D)")
        ax.set_xlabel("PC1"); ax.set_ylabel("PC2")
        plt.colorbar(sc, label="Cluster")
        st.pyplot(fig)

    # So s√°nh nhanh c·∫£ hai thu·∫≠t to√°n
    if st.button("Ch·∫°y c·∫£ hai & so s√°nh"):
        kmeans = KMeans(n_clusters=int(df["Type"].nunique()), random_state=42, n_init=20)
        km_labels = kmeans.fit_predict(X_scaled)
        db = DBSCAN(eps=eps, min_samples=min_samples)
        db_labels = db.fit_predict(X_scaled)
        km_eval = evaluate_clustering(y, km_labels)
        db_eval = evaluate_clustering(y, db_labels)
        compare_df = pd.DataFrame([
            ["K-Means", km_eval["F1_macro"], km_eval["ARI"], km_eval["NMI"]],
            ["DBSCAN", db_eval["F1_macro"], db_eval["ARI"], db_eval["NMI"]],
        ], columns=["Algorithm", "F1_macro", "ARI", "NMI"])
        st.subheader("So s√°nh K-Means vs DBSCAN")
        st.dataframe(compare_df, width="stretch")
        st.download_button("T·∫£i so s√°nh (CSV)", compare_df.to_csv(index=False), file_name="clustering_compare.csv", mime="text/csv")
