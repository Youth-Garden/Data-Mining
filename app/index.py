import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from pathlib import Path
from typing import Tuple, Dict, Any, List, Optional
import subprocess

# Local modules
from features.data import load_data, scale_continuous
from features.viz import run_pca, run_tsne
from features.clustering import evaluate_clustering
from features.modeling import run_classification
from features.utils import auto_table_height
from features.notebook_runner import run_notebook, notebook_to_html

# === C·∫•u h√¨nh trang v√† CSS ===

st.set_page_config(
    page_title="Glass Data Mining Demo", 
    layout="wide",
    page_icon="üìä" # Th√™m icon chuy√™n nghi·ªáp
)
sns.set_style("whitegrid")

def load_css(file_name: str) -> None:
    """
    T·∫£i file CSS t√πy ch·ªânh v√† ch√®n v√†o <head> c·ªßa ·ª©ng d·ª•ng Streamlit.
    ...
    """
    try:
        css_path = Path(__file__).parent / file_name
        # Th√™m encoding="utf-8" ƒë·ªÉ ƒë·ªçc file
        with open(css_path, encoding="utf-8") as f:  # <--- ƒê√É S·ª¨A
            css = f.read()
        st.markdown(f'<style>{css}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {file_name} t·∫°i {css_path}")

load_css("style.css")

def ensure_chromium_installed():
    """Ensure Playwright's Chromium is installed before using nbconvert[webpdf]."""
    try:
        from playwright._impl._driver import compute_driver_executable
        compute_driver_executable()
    except Exception:
        print("Installing Chromium for Playwright...")
        subprocess.run(["python", "-m", "playwright", "install", "chromium", "--with-deps"], check=True)

ensure_chromium_installed()


# === Caching (L∆∞u ƒë·ªám) cho c√°c h√†m t·ªën t√†i nguy√™n ===

@st.cache_data
def get_data() -> pd.DataFrame:
    """
    T·∫£i v√† cache d·ªØ li·ªáu th√¥ t·ª´ file.

    Returns:
        pd.DataFrame: DataFrame ƒë√£ ƒë∆∞·ª£c t·∫£i v√† (c√≥ th·ªÉ) ƒë√£ l√†m s·∫°ch.
    
    Raises:
        st.stop: N·∫øu kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c file d·ªØ li·ªáu.
    """
    try:
        df = load_data()
        return df
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu: {e}")
        st.stop()

@st.cache_data
def get_scaled_data(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    T√°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu t·ª´ DataFrame.

    Args:
        df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu th√¥.

    Returns:
        Tuple[np.ndarray, np.ndarray, np.ndarray]: 
            - X_cont (np.ndarray): C√°c ƒë·∫∑c tr∆∞ng li√™n t·ª•c (ch∆∞a scale).
            - X_scaled (np.ndarray): C√°c ƒë·∫∑c tr∆∞ng li√™n t·ª•c (ƒë√£ scale).
            - y (np.ndarray): M·∫£ng ch·ª©a nh√£n (Type).
    """
    X_cont, X_scaled = scale_continuous(df)
    y = df["Type"].values
    return X_cont, X_scaled, y

@st.cache_data
def get_pca(X_scaled: np.ndarray) -> Tuple[np.ndarray, PCA]:
    """
    Ch·∫°y thu·∫≠t to√°n PCA tr√™n d·ªØ li·ªáu ƒë√£ scale v√† cache k·∫øt qu·∫£.

    Args:
        X_scaled (np.ndarray): D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.

    Returns:
        Tuple[np.ndarray, PCA]:
            - np.ndarray: D·ªØ li·ªáu ƒë√£ gi·∫£m chi·ªÅu (2D).
            - PCA: ƒê·ªëi t∆∞·ª£ng PCA ƒë√£ fit.
    """
    return run_pca(X_scaled)

@st.cache_data
def get_tsne(X_scaled: np.ndarray) -> np.ndarray:
    """
    Ch·∫°y thu·∫≠t to√°n t-SNE tr√™n d·ªØ li·ªáu ƒë√£ scale v√† cache k·∫øt qu·∫£.

    Args:
        X_scaled (np.ndarray): D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.

    Returns:
        np.ndarray: D·ªØ li·ªáu ƒë√£ gi·∫£m chi·ªÅu (2D).
    """
    return run_tsne(X_scaled)


# === C√°c h√†m hi·ªÉn th·ªã cho t·ª´ng m·ª•c ===

def display_sidebar() -> None:
    """
    Hi·ªÉn th·ªã thanh sidebar ƒëi·ªÅu h∆∞·ªõng (m·ª•c l·ª•c) c·ªßa ·ª©ng d·ª•ng.
    """
    st.sidebar.title("M·ª•c l·ª•c")
    # st.sidebar.markdown("### M·ª•c l·ª•c")
    st.sidebar.markdown(
        """
        - [Gi·ªõi thi·ªáu](#gioi-thieu)
        - [1. Kh·∫£o s√°t d·ªØ li·ªáu](#khao-sat-du-lieu)
        - [2. Tr·ª±c quan h√≥a](#truc-quan-hoa)
        - [3. Ph√¢n lo·∫°i](#phan-loai)
        - [4. Gom c·ª•m](#gom-cum)
        """
    )
    st.sidebar.markdown("---")
    st.sidebar.caption("Source: glass-data.csv")

def display_introduction(df: pd.DataFrame) -> None:
    """
    Hi·ªÉn th·ªã ph·∫ßn Gi·ªõi thi·ªáu, ƒê·ªÅ b√†i, c√°c ch·ªâ s·ªë t·ªïng quan 
    v√† c√°c n√∫t t·∫£i d·ªØ li·ªáu.

    Args:
        df (pd.DataFrame): DataFrame d·ªØ li·ªáu ch√≠nh ƒë·ªÉ l·∫•y th√¥ng tin 
                           t·ªïng quan (shape, nunique).
    """
    st.markdown('<div id="gioi-thieu" class="anchor"></div>', unsafe_allow_html=True)
    st.title("Glass Data Mining Demo")
    st.markdown(
        """
        ·ª®ng d·ª•ng web tr√¨nh di·ªÖn c√°c b∆∞·ªõc khai ph√° d·ªØ li·ªáu tr√™n b·ªô d·ªØ li·ªáu k√≠nh:
        - Kh·∫£o s√°t d·ªØ li·ªáu c∆° b·∫£n (shape, dtype, th·ªëng k√™, ph√¢n b·ªë nh√£n)
        - Tr·ª±c quan h√≥a v·ªõi PCA v√† t-SNE
        - Hu·∫•n luy·ªán v√† so s√°nh c√°c m√¥ h√¨nh ph√¢n lo·∫°i (KNN, Random Forest, SVM)
        - Gom c·ª•m v·ªõi K-Means v√† DBSCAN, k√®m c√°c ƒë·ªô ƒëo F1, ARI, NMI
        """
    )

    c1, c2, c3 = st.columns(3)
    with c1:
        st.metric("S·ªë m·∫´u", df.shape[0])
    with c2:
        st.metric("S·ªë thu·ªôc t√≠nh", df.shape[1])
    with c3:
        st.metric("S·ªë l·ªõp (Type)", int(df["Type"].nunique()))

    st.subheader("ƒê·ªÅ b√†i")
    st.markdown(
        """
        1. Kh·∫£o s√°t v√† x·ª≠ l√Ω d·ªØ li·ªáu: k√≠ch th∆∞·ªõc, ki·ªÉu d·ªØ li·ªáu, ph√¢n b·ªë nh√£n, th·ªëng k√™.
        2. Tr·ª±c quan h√≥a: gi·∫£m chi·ªÅu (PCA, t-SNE) v√† bi·ªÉu di·ªÖn ph√¢n b·ªë.
        3. Ph√¢n lo·∫°i: so s√°nh KNN, Random Forest, SVM b·∫±ng 10-fold CV (F1 Macro).
        4. Gom c·ª•m: K-Means v√† DBSCAN, ƒë√°nh gi√° b·∫±ng F1 Macro, ARI, NMI.
        """
    )

    st.subheader("Xu·∫•t/ t·∫£i d·ªØ li·ªáu")
    col_a, col_b = st.columns(2)
    with col_a:
        st.write("T·∫£i b·∫£n CSV g·ªëc (tab-separated)")
        try:
            with open("glass-data.csv", "rb") as f:
                st.download_button("T·∫£i glass-data.csv", f, file_name="glass-data.csv", mime="text/tab-separated-values")
        except Exception:
            st.caption("Kh√¥ng t√¨m th·∫•y glass-data.csv trong th∆∞ m·ª•c hi·ªán t·∫°i.")
    with col_b:
        st.write("T·∫£i b·∫£n CSV ƒë√£ chu·∫©n h√≥a t√™n c·ªôt")
        cleaned_csv = df.to_csv(index=False)
        st.download_button("T·∫£i cleaned_glass.csv", cleaned_csv, file_name="cleaned_glass.csv", mime="text/csv")

    st.markdown("---")

    with st.expander("K·∫øt qu·∫£ t·ª´ Notebook", expanded=False):
        # Kh·ªüi t·∫°o bi·∫øn trong session_state n·∫øu ch∆∞a c√≥
        if "notebook_ran" not in st.session_state:
            st.session_state.notebook_ran = False
        if "executed_notebook" not in st.session_state:
            st.session_state.executed_notebook = None
        if "pdf_path" not in st.session_state:
            st.session_state.pdf_path = None
        if "html_preview" not in st.session_state:
            st.session_state.html_preview = None

        # N√∫t ch·∫°y notebook
        if st.button("Ch·∫°y Notebook", key="run_notebook"):
            try:
                with st.spinner("ƒêang ch·∫°y notebook..."):
                    out_nb = run_notebook(
                        "main.ipynb",
                        "outputs/main_executed.ipynb",
                        kernel_name=None
                    )

                    # T·∫°o HTML preview
                    try:
                        html_preview = notebook_to_html(out_nb)
                    except Exception:
                        html_preview = None

                    # T·∫°o PDF
                    pdf_path = None
                    try:
                        from features.notebook_runner import notebook_to_pdf
                        pdf_path = notebook_to_pdf(out_nb, "outputs/main_executed.pdf")
                    except Exception as e:
                        st.warning(f"Kh√¥ng th·ªÉ t·∫°o PDF: {e}")

                    # L∆∞u v√†o session_state
                    st.session_state.executed_notebook = out_nb
                    st.session_state.pdf_path = pdf_path
                    st.session_state.html_preview = html_preview
                    st.session_state.notebook_ran = True


            except Exception as e:
                st.error(f"L·ªói khi ch·∫°y notebook: {e}\nC√†i ƒë·∫∑t: pip install nbformat nbclient nbconvert")

        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ ch·∫°y ---
        if st.session_state.notebook_ran:
            out_nb = st.session_state.executed_notebook
            pdf_path = st.session_state.pdf_path
            html_preview = st.session_state.html_preview

            st.success("Notebook ƒë√£ ch·∫°y xong")

            col_dl1, col_dl2 = st.columns(2)
            with col_dl1:
                if out_nb and os.path.exists(out_nb):
                    with open(out_nb, "rb") as f:
                        st.download_button(
                            "T·∫£i Notebook",
                            f,
                            file_name="main_executed.ipynb",
                            mime="application/x-ipynb+json",
                            use_container_width=True,
                        )
            with col_dl2:
                if pdf_path and os.path.exists(pdf_path):
                    with open(pdf_path, "rb") as f:
                        st.download_button(
                            "T·∫£i PDF",
                            f,
                            file_name="main_executed.pdf",
                            mime="application/pdf",
                            use_container_width=True,
                        )
                else:
                    st.info("PDF kh√¥ng kh·∫£ d·ª•ng")

            if html_preview:
                with st.expander("Xem tr∆∞·ªõc chi ti·∫øt notebook (HTML)", expanded=False):
                    st.components.v1.html(html_preview, height=700, scrolling=True)
        else:
            st.info("Nh·∫•n n√∫t **'Ch·∫°y Notebook'** ƒë·ªÉ th·ª±c thi v√† xem k·∫øt qu·∫£.")


def display_eda(df: pd.DataFrame) -> None:
    """
    Hi·ªÉn th·ªã ph·∫ßn Kh·∫£o s√°t d·ªØ li·ªáu (EDA - Exploratory Data Analysis).

    Bao g·ªìm: B·∫£ng d·ªØ li·ªáu, th√¥ng tin chung (shape, dtypes),
    ph√¢n b·ªë nh√£n v√† th·ªëng k√™ m√¥ t·∫£.

    Args:
        df (pd.DataFrame): DataFrame d·ªØ li·ªáu ch√≠nh ƒë·ªÉ hi·ªÉn th·ªã.
    """
    st.markdown('<div id="khao-sat-du-lieu" class="anchor"></div>', unsafe_allow_html=True)
    st.header("1. Kh·∫£o s√°t d·ªØ li·ªáu")

    st.subheader("B·∫£ng d·ªØ li·ªáu")
    st.dataframe(df, use_container_width=True, height=400)

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Th√¥ng tin chung")
        info_data = pd.DataFrame({
            'Thu·ªôc t√≠nh': ['S·ªë m·∫´u', 'S·ªë thu·ªôc t√≠nh', 'S·ªë l·ªõp (Type)'],
            'Gi√° tr·ªã': [int(df.shape[0]), int(df.shape[1]), int(df["Type"].nunique())]
        })
        st.dataframe(info_data, use_container_width=True, hide_index=True, height=150)
        
        st.subheader("**Ki·ªÉu d·ªØ li·ªáu**")
        dtype_data = pd.DataFrame({
            'C·ªôt': df.dtypes.index.tolist(),
            'Ki·ªÉu': [str(dt) for dt in df.dtypes.values]
        })
        st.dataframe(dtype_data, use_container_width=True, hide_index=True, height=300)

    with col2:
        st.subheader("Ph√¢n b·ªë nh√£n")
        type_counts = df["Type"].value_counts().sort_index()
        st.bar_chart(type_counts, use_container_width=True, height=150)
        
        st.subheader("Th·ªëng k√™ m√¥ t·∫£")
        st.dataframe(df.describe().T[['mean', 'std', 'min', 'max']], use_container_width=True, height=300)

def display_visualization(df: pd.DataFrame, X_scaled: np.ndarray) -> None:
    """
    Hi·ªÉn th·ªã ph·∫ßn Tr·ª±c quan h√≥a (PCA v√† t-SNE).
    
    S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ cache t·ª´ `get_pca` v√† `get_tsne`.

    Args:
        df (pd.DataFrame): DataFrame d·ªØ li·ªáu (ƒë·ªÉ l·∫•y nh√£n 'Type').
        X_scaled (np.ndarray): D·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a (ƒë·ªÉ truy·ªÅn v√†o 
                               h√†m cache).
    """
    st.markdown('<div id="truc-quan-hoa" class="anchor"></div>', unsafe_allow_html=True)
    st.header("2. Tr·ª±c quan h√≥a")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("PCA 2D")
        with st.spinner("T√≠nh to√°n PCA..."):
            X_pca, pca = get_pca(X_scaled) # D√πng h√†m ƒë√£ cache
        
        fig, ax = plt.subplots(figsize=(7, 5.5))
        for t in sorted(df["Type"].unique()):
            mask = df["Type"] == t
            ax.scatter(
                X_pca[mask, 0], X_pca[mask, 1],
                s=70, label=f"Type {t}", alpha=0.75,
                edgecolors="#555555", linewidths=0.4,
            )
        ax.set_xlabel(f"PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)", fontsize=11)
        ax.set_ylabel(f"PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)", fontsize=11)
        ax.set_title("Bi·ªÉu ƒë·ªì PCA", fontsize=12, fontweight='bold')
        ax.legend(loc='best', framealpha=0.9)
        ax.grid(True, alpha=0.25, linestyle='--')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        plt.tight_layout()
        st.pyplot(fig)

    with col2:
        st.subheader("t-SNE 2D")
        with st.spinner("T√≠nh to√°n t-SNE..."):
            X_tsne = get_tsne(X_scaled) # D√πng h√†m ƒë√£ cache
        
        fig, ax = plt.subplots(figsize=(7, 5.5))
        for t in sorted(df["Type"].unique()):
            mask = df["Type"] == t
            ax.scatter(
                X_tsne[mask, 0], X_tsne[mask, 1],
                s=70, label=f"Type {t}", alpha=0.75,
                edgecolors="#555555", linewidths=0.4,
            )
        ax.set_xlabel("t-SNE 1", fontsize=11)
        ax.set_ylabel("t-SNE 2", fontsize=11)
        ax.set_title("Bi·ªÉu ƒë·ªì t-SNE", fontsize=12, fontweight='bold')
        ax.legend(loc='best', framealpha=0.9)
        ax.grid(True, alpha=0.25, linestyle='--')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        plt.tight_layout()
        st.pyplot(fig)

def display_classification(df: pd.DataFrame) -> None:
    """
    Hi·ªÉn th·ªã giao di·ªán v√† x·ª≠ l√Ω logic cho ph·∫ßn Ph√¢n lo·∫°i (Classification).

    Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn s·ªë K-Fold v√† ch·∫°y so s√°nh c√°c m√¥ h√¨nh.
    K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u v√†o `st.session_state`.

    Args:
        df (pd.DataFrame): DataFrame d·ªØ li·ªáu (ƒë·ªÉ truy·ªÅn v√†o 
                           h√†m `run_classification`).
    """
    st.markdown('<div id="phan-loai" class="anchor"></div>', unsafe_allow_html=True)
    st.header("3. Ph√¢n lo·∫°i (Classification)")

    col_cf1, col_cf2 = st.columns([4, 1])
    with col_cf1:
        cv_k = st.slider("KFold splits", min_value=3, max_value=10, value=10, step=1, key="cv_slider")
    with col_cf2:
        st.write("")  # Spacer
        run_classification_btn = st.button("Ch·∫°y", key="run_classification")

    if run_classification_btn:
        with st.spinner("ƒêang hu·∫•n luy·ªán c√°c m√¥ h√¨nh..."):
            progress = st.progress(0)
            def _cb(i: int, total: int):
                progress.progress(min(int(i / total * 100), 99))
            
            results = run_classification(df, cv_k=cv_k, progress_callback=_cb)
            progress.progress(100)
            st.session_state['classification_results'] = results

    if 'classification_results' in st.session_state:
        st.success("Ph√¢n lo·∫°i ho√†n th√†nh")
        st.subheader("K·∫øt qu·∫£")
        st.dataframe(st.session_state['classification_results'], use_container_width=True)

def display_clustering(X_scaled: np.ndarray, y: np.ndarray) -> None:
    """
    Hi·ªÉn th·ªã giao di·ªán v√† x·ª≠ l√Ω logic cho ph·∫ßn Gom c·ª•m (Clustering).

    Bao g·ªìm K-Means v√† DBSCAN. Ng∆∞·ªùi d√πng c√≥ th·ªÉ t∆∞∆°ng t√°c v·ªõi
    tham s·ªë v√† xem k·∫øt qu·∫£ (ch·ªâ s·ªë, bi·ªÉu ƒë·ªì).

    Args:
        X_scaled (np.ndarray): D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a.
        y (np.ndarray): Nh√£n (ground-truth) c·ªßa d·ªØ li·ªáu.
    """
    st.markdown('<div id="gom-cum" class="anchor"></div>', unsafe_allow_html=True)
    st.header("4. Gom c·ª•m (Clustering)")

    col_cluster1, col_cluster2 = st.columns(2)

    # --- K-MEANS ---
    with col_cluster1:
        st.subheader("K-Means")
        n_clusters_kmeans = st.slider("S·ªë c·ª•m K-Means", min_value=2, max_value=10, value=6, step=1, key="kmeans_clusters")
        run_kmeans = st.button("Ch·∫°y", key="btn_kmeans")
        
        result_container_km = st.container(border=False) # container cho k·∫øt qu·∫£
        
        if run_kmeans:
            with st.spinner("ƒêang ch·∫°y K-Means..."):
                kmeans = KMeans(n_clusters=n_clusters_kmeans, random_state=42, n_init=20)
                km_labels = kmeans.fit_predict(X_scaled)
                km_eval = evaluate_clustering(y, km_labels)
                
                X_pca, _ = get_pca(X_scaled) # D√πng l·∫°i PCA ƒë√£ cache
                
                fig = plt.figure(figsize=(7, 6))
                ax = fig.add_subplot(111)
                scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=km_labels, cmap="tab10", 
                                    s=60, alpha=0.7, edgecolors="#555555", linewidths=0.5)
                ax.set_xlabel("PC1", fontsize=10)
                ax.set_ylabel("PC2", fontsize=10)
                ax.set_title("K-Means Clustering", fontsize=11, fontweight='bold')
                ax.grid(True, alpha=0.25, linestyle='--')
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                plt.colorbar(scatter, ax=ax, label="C·ª•m", fraction=0.046, pad=0.04)
                fig.tight_layout()
                
                st.session_state['kmeans_eval'] = km_eval
                st.session_state['kmeans_fig'] = fig
        
        with result_container_km:
            if 'kmeans_eval' in st.session_state:
                st.success("K-Means ho√†n th√†nh")
                col_k1, col_k2, col_k3 = st.columns(3)
                col_k1.metric("F1", f"{st.session_state['kmeans_eval']['F1_macro']:.3f}")
                col_k2.metric("ARI", f"{st.session_state['kmeans_eval']['ARI']:.3f}")
                col_k3.metric("NMI", f"{st.session_state['kmeans_eval']['NMI']:.3f}")
                st.pyplot(st.session_state['kmeans_fig'], use_container_width=False)

    # --- DBSCAN ---
    with col_cluster2:
        st.subheader("DBSCAN")
        col_d1, col_d2 = st.columns(2)
        with col_d1:
            eps_dbscan = st.slider("B√°n k√≠nh epsilon (Œµ)", 0.3, 2.0, 1.0, 0.1, key="dbscan_eps")
        with col_d2:
            min_samples_db = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu (min_samples)", 3, 20, 5, 1, key="dbscan_min")

        run_dbscan = st.button("Ch·∫°y", key="btn_dbscan")
        result_container_db = st.container(border=False) # container cho k·∫øt qu·∫£
        
        if run_dbscan:
            with st.spinner("ƒêang ch·∫°y DBSCAN..."):
                db = DBSCAN(eps=eps_dbscan, min_samples=min_samples_db)
                db_labels = db.fit_predict(X_scaled)
                db_eval = evaluate_clustering(y, db_labels)
                n_clusters_db = len(set(db_labels)) - (1 if -1 in db_labels else 0)
                n_noise = list(db_labels).count(-1)
                
                X_pca, _ = get_pca(X_scaled) # D√πng l·∫°i PCA ƒë√£ cache
                
                fig = plt.figure(figsize=(7, 6))
                ax = fig.add_subplot(111)
                scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=db_labels, cmap="tab10",
                                    s=60, alpha=0.7, edgecolors="#555555", linewidths=0.5)
                ax.set_xlabel("PC1", fontsize=10)
                ax.set_ylabel("PC2", fontsize=10)
                ax.set_title("DBSCAN Clustering", fontsize=11, fontweight='bold')
                ax.grid(True, alpha=0.25, linestyle='--')
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                plt.colorbar(scatter, ax=ax, label="C·ª•m", fraction=0.046, pad=0.04)
                fig.tight_layout()
                
                st.session_state['dbscan_eval'] = db_eval
                st.session_state['dbscan_clusters'] = n_clusters_db
                st.session_state['dbscan_noise'] = n_noise
                st.session_state['dbscan_fig'] = fig
        
        with result_container_db:
            if 'dbscan_eval' in st.session_state:
                st.success("DBSCAN ho√†n th√†nh")
                cols = st.columns(5)
                cols[0].metric("F1", f"{st.session_state['dbscan_eval']['F1_macro']:.3f}")
                cols[1].metric("ARI", f"{st.session_state['dbscan_eval']['ARI']:.3f}")
                cols[2].metric("NMI", f"{st.session_state['dbscan_eval']['NMI']:.3f}")
                cols[3].metric("C·ª•m", st.session_state['dbscan_clusters'])
                cols[4].metric("Nhi·ªÖu", st.session_state['dbscan_noise'])
                
                st.pyplot(st.session_state['dbscan_fig'], use_container_width=False)


# === H√†m main ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng ===

def main() -> None:
    """
    H√†m ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô ·ª©ng d·ª•ng Streamlit.
    
    T·∫£i d·ªØ li·ªáu, sau ƒë√≥ g·ªçi c√°c h√†m `display_` ƒë·ªÉ
    v·∫Ω l√™n t·ª´ng ph·∫ßn c·ªßa giao di·ªán.
    """
    
    # T·∫£i d·ªØ li·ªáu (ƒë√£ cache)
    df = get_data()
    X_cont, X_scaled, y = get_scaled_data(df)

    # Hi·ªÉn th·ªã c√°c th√†nh ph·∫ßn
    display_sidebar()
    display_introduction(df)
    display_eda(df)
    display_visualization(df, X_scaled)
    display_classification(df)
    display_clustering(X_scaled, y)

if __name__ == "__main__":
    main()